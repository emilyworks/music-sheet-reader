{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6vFpKx7aLMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c253cb36-850a-4528-8d29-20fee9921562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 470584, done.\u001b[K\n",
            "remote: Counting objects: 100% (51042/51042), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2377/2377), done.\u001b[K\n",
            "remote: Total 470584 (delta 48741), reused 50832 (delta 48588), pack-reused 419542\u001b[K\n",
            "Receiving objects: 100% (470584/470584), 924.23 MiB | 22.47 MiB/s, done.\n",
            "Resolving deltas: 100% (437844/437844), done.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import torch\n",
        "from IPython.display import Image\n",
        "import json\n",
        "import torchvision.models as models\n",
        "import torchvision.models.segmentation.lraspp\n",
        "import torch\n",
        "!git clone https://github.com/pytorch/vision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install swig\n",
        "!git clone https://github.com/yvan674/obb_anns\n",
        "!python3 setup.py develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daRq-P6hn5Dl",
        "outputId": "ec649716-920c-4935-9a42-69e0be07d61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 3s (434 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Cloning into 'obb_anns'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 269 (delta 77), reused 70 (delta 70), pack-reused 183\u001b[K\n",
            "Receiving objects: 100% (269/269), 958.68 KiB | 3.27 MiB/s, done.\n",
            "Resolving deltas: 100% (130/130), done.\n",
            "python3: can't open file '/content/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh /content/ds2_dense/deepscores_train.json"
      ],
      "metadata": {
        "id": "YJu0JXwsn_mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = requests.get('https://zenodo.org/records/4012193/files/ds2_dense.tar.gz?download=1')\n",
        "\n",
        "with open('ds2_dense.tar.gz', 'wb') as f:\n",
        "    f.write(r.content)\n",
        "with tarfile.open('ds2_dense.tar.gz', 'r:gz') as tar:\n",
        "    tar.extractall()"
      ],
      "metadata": {
        "id": "vY0OS-Ibbg2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open('/content/ds2_dense/deepscores_train.json', 'r') as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "NY_kFhBMwM4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(len(list(data['categories'].keys())))\n",
        "\n",
        "\n",
        "model = torchvision.models.segmentation.lraspp.LRASPP(backbone=torchvision.models.mobilenetv3.MobileNetV3,\n",
        "                                                      low_channels=10, high_channels=10, num_classes=len(list(data['categories'].keys())))\n",
        "\n",
        "!torchrun --nproc_per_node=8 vision/references/segmentation/train.py --dataset coco -b 4 --model lraspp_mobilenet_v3_large --wd 0.000001 --weights-backbone MobileNet_V3_Large_Weights.IMAGENET1K_V1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSfNreDwwmd-",
        "outputId": "dd7920f1-3fae-457d-cda2-f332c558d8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208\n",
            "[2024-03-02 17:36:52,007] torch.distributed.run: [WARNING] \n",
            "[2024-03-02 17:36:52,007] torch.distributed.run: [WARNING] *****************************************\n",
            "[2024-03-02 17:36:52,007] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "[2024-03-02 17:36:52,007] torch.distributed.run: [WARNING] *****************************************\n",
            "[2024-03-02 17:37:28,643] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n",
            "[2024-03-02 17:37:28,644] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25217 closing signal SIGINT\n",
            "[2024-03-02 17:37:28,644] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25218 closing signal SIGINT\n",
            "[2024-03-02 17:37:28,644] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25219 closing signal SIGINT\n",
            "[2024-03-02 17:37:28,644] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25220 closing signal SIGINT\n",
            "[2024-03-02 17:37:28,644] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25221 closing signal SIGINT\n",
            "[2024-03-02 17:37:28,644] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25222 closing signal SIGINT\n",
            "[2024-03-02 17:37:28,644] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25223 closing signal SIGINT\n",
            "[2024-03-02 17:37:28,645] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25224 closing signal SIGINT\n",
            "[2024-03-02 17:37:28,646] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25217 closing signal SIGTERM\n",
            "[2024-03-02 17:37:28,646] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25218 closing signal SIGTERM\n",
            "[2024-03-02 17:37:28,646] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25219 closing signal SIGTERM\n",
            "[2024-03-02 17:37:28,647] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25220 closing signal SIGTERM\n",
            "[2024-03-02 17:37:28,647] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25221 closing signal SIGTERM\n",
            "[2024-03-02 17:37:28,647] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25222 closing signal SIGTERM\n",
            "[2024-03-02 17:37:28,647] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25223 closing signal SIGTERM\n",
            "[2024-03-02 17:37:28,647] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 25224 closing signal SIGTERM\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 736, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 877, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 62, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 25198 got signal: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/torchrun\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 806, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 797, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 255, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/metrics/api.py\", line 124, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 743, in run\n",
            "    self._shutdown(e.sigval)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 289, in _shutdown\n",
            "    self._pcontext.close(death_sig)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 331, in close\n",
            "    self._close(death_sig=death_sig, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 713, in _close\n",
            "    handler.proc.wait(time_to_wait)\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1209, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1953, in _wait\n",
            "    time.sleep(delay)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 62, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 25198 got signal: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import DeepScoresV2\n",
        "from engine import train_one_epoch, evaluate\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # Add more transforms as needed\n",
        "])\n",
        "\n",
        "# Load DeepScoresV2 dataset\n",
        "dataset_train = DeepScoresV2(root='./data', train=True, transform=transform)\n",
        "dataset_test = DeepScoresV2(root='./data', train=False, transform=transform)\n",
        "\n",
        "# Define data loaders\n",
        "data_loader_train = DataLoader(dataset_train, batch_size=2, shuffle=True, num_workers=4)\n",
        "data_loader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "# Load pre-trained Mask R-CNN model\n",
        "model = MaskRCNN(\n",
        "    backbone=torchvision.models.resnet50(pretrained=True).backbone,\n",
        "    num_classes=91  # 90 classes + background\n",
        ")\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "# Move model to device (CPU or GPU)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=10)\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # Evaluation\n",
        "    evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'mask_rcnn_deepscoresv2.pth')\n"
      ],
      "metadata": {
        "id": "Qr53qcDPyle9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}